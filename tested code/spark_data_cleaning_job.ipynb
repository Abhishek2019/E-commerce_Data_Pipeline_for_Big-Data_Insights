{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e632e87f-cd93-46ab-9cd4-62a9d2179568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a168cb78-c0cc-4404-ac59-6706cca7f69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data :  8\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.context import SparkContext\n",
    "from LockQueue_module import LockQueue\n",
    "import string\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# import json\n",
    "# from bson import ObjectId\n",
    "\n",
    "# class JSONEncoder(json.JSONEncoder):\n",
    "#     def default(self, o):\n",
    "#         if isinstance(o, ObjectId):\n",
    "#             return str(o)\n",
    "#         return json.JSONEncoder.default(self, o)\n",
    "\n",
    "\n",
    "def cleaning_func(x):\n",
    "\n",
    "    # lower case\n",
    "    # replace & with and\n",
    "    # remove punctuation\n",
    "    \n",
    "    x[\"fullDocument\"][\"title\"] = x[\"fullDocument\"][\"title\"].lower().replace(\"&\",\"and\").translate(str.maketrans('', '', string.punctuation))\n",
    "    if str(x[\"fullDocument\"][\"current_price\"]).lower() == 'nan':\n",
    "        x[\"fullDocument\"][\"current_price\"] = 0\n",
    "\n",
    "    if str(x[\"fullDocument\"][\"previous_price\"]).lower() == 'nan':\n",
    "        x[\"fullDocument\"][\"previous_price\"] = 0\n",
    "\n",
    "    return x[\"fullDocument\"]\n",
    "    # return JSONEncoder().encode(x[\"fullDocument\"])\n",
    "\n",
    "\n",
    "lq = LockQueue()\n",
    "\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    global data\n",
    "    data = lq.get_read_queue()\n",
    "\n",
    "    if(type(data) == type([])):\n",
    "        break\n",
    "if(data !=[]):\n",
    "    print(\"Length of the data : \",len(data))\n",
    "    spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"mongodbtest1\") \\\n",
    "    .master(\"spark://10.1.174.144:7077\")\\\n",
    "    .config(\"spark.mongodb.read.uri\", \"mongodb://abhi_1:60000/shardDB.asofashion_2\") \\\n",
    "    .config(\"spark.mongodb.write.uri\", \"mongodb://abhi_1:60000/shardDB.asofashion_clean\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.13:10.2.2') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    sc = spark.sparkContext\n",
    "    clean_doc = sc.parallelize(data).map(cleaning_func).collect()\n",
    "\n",
    "    client = MongoClient(\"149.165.172.75\", 60000)\n",
    "    db = client.shardDB\n",
    "    \n",
    "    collection = db[\"asofashion_clean\"]\n",
    "\n",
    "\n",
    "    collection.insert_many(clean_doc)\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"No Data for Spark Job to Execute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9e36276c-bee4-4658-aa10-45e2727121dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean_doc.collect()\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b7131090-9a9b-46d3-981e-d67f27ae4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = spark.read.json(clean_doc)\n",
    "# ,multiLine=True\n",
    "# k.write.format(\"mongodb\")\\\n",
    "#                .mode(\"append\")\\\n",
    "#                .option(\"connection.uri\", \"mongodb://abhi_1:60000/\")\\\n",
    "#                .option(\"database\", \"shardDB\")\\\n",
    "#                .option(\"collection\", \"asofashion_clean\")\\\n",
    "#                .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d9a02b69-6f83-4185-a9d3-dd54ca82cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('66186f4c8a54e2756c1f46c1'), ObjectId('66186f4c8a54e2756c1f46c2'), ObjectId('66186f4c8a54e2756c1f46c3'), ObjectId('66186f4c8a54e2756c1f46c4'), ObjectId('66186f4c8a54e2756c1f46c5'), ObjectId('66186f4c8a54e2756c1f46c6'), ObjectId('66186f4c8a54e2756c1f46c7'), ObjectId('66186f4c8a54e2756c1f46c8')], acknowledged=True)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# client = MongoClient(\"149.165.172.75\", 60000)\n",
    "# db = client.shardDB\n",
    "\n",
    "# collection = db[\"asofashion_clean\"]\n",
    "\n",
    "\n",
    "# collection.insert_many(clean_doc.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "544a13f8-35c9-45f8-946b-790449031d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4e91a-02ac-4041-b06e-5c5353897654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb93086-ab99-4c13-96b5-3b22e84b3149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "db1db87c-155a-4083-8dc7-b4d211544412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "647b3247-c7b4-40d5-a0d5-5c04cd934a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession \\\n",
    "# .builder \\\n",
    "# .appName(\"mongodbtest1\") \\\n",
    "# .master(\"spark://10.1.174.144:7077\")\\\n",
    "# .config(\"spark.mongodb.read.uri\", \"mongodb://abhi_1:60000/shardDB.asofashion_2\") \\\n",
    "# .config(\"spark.mongodb.write.uri\", \"mongodb://abhi_1:60000/shardDB.asofashion_clean\") \\\n",
    "# .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.13:10.2.2') \\\n",
    "# .getOrCreate()\n",
    "\n",
    "\n",
    "# # sc = SparkContext(\"spark://10.1.174.144:7077\")\n",
    "# # z = spark.sparkContext.parallelize([1,2,3,4])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fe7882c9-3d31-4053-8cde-4ca18822b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "628ab3e2-95c4-4917-a4dc-1a944bc64bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7fc83dc2-7237-4d34-b727-b8541783a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "07cc1122-d445-4eab-9f5b-bee057cfb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d4986-1ea3-4ca1-a100-7eabfe887437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d2f80e1f-7950-4d19-bd5e-31f77ab8f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.clustering import LDA\n",
    "\n",
    "# # Loads data.\n",
    "# dataset = spark.read.format(\"libsvm\").load(\"sample_lda_libsvm_data.txt\")\n",
    "\n",
    "# # Trains a LDA model.\n",
    "# lda = LDA(k=10, maxIter=10)\n",
    "# model = lda.fit(dataset)\n",
    "\n",
    "# ll = model.logLikelihood(dataset)\n",
    "# lp = model.logPerplexity(dataset)\n",
    "# print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "# print(\"The upper bound on perplexity: \" + str(lp))\n",
    "\n",
    "# # Describe topics.\n",
    "# topics = model.describeTopics(3)\n",
    "# print(\"The topics described by their top-weighted terms:\")\n",
    "# topics.show(truncate=False)\n",
    "\n",
    "# # Shows the result\n",
    "# transformed = model.transform(dataset)\n",
    "# transformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "524f0407-0a06-476c-9c8b-19f607f0478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ede0f-db7a-45df-834a-66ffd02996cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819cadf-6be5-4e6e-b54a-4cbb13b1a81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d76a56c-28c3-4b6e-a857-18e6cc004ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
